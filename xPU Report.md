# xPU Report #

现如今， 各种计算单元层出不穷，他们大多都以xPU（Processing unit）的方式命名，其中除了最为我们所熟知的CPU与GPU之外，还有 TPU, NPU，DPU等等，我们下面就分别来简单报告一下它们的具体情况。

---

## CPU ##
### 简介
中央处理器 （Central Processing Unit，CPU），是计算机的主要设备之一，功能主要是解释计算机指令以及处理计算机软件中的数据。计算机的可编程性主要是指对中央处理器的编程。1970年代以前，中央处理器由多个独立单元构成，后来发展出由集成电路制造的中央处理器，這些高度收縮的元件就是所謂的微处理器，其中分出的中央处理器最為复杂的电路可以做成单一微小功能强大的单元。

中央处理器主要包括运算器（算术逻辑运算单元，ALU，Arithmetic Logic Unit）和高速缓冲存储器（Cache）及实现它们之间联系的数据（Data）、控制及状态的总线（Bus）。它与内部存储器（Memory）和输入/输出（I/O）设备合称为电子计算机三大核心部件。

简单来说就是：计算单元、控制单元和存储单元，架构如下图所示：

![此处输入图片的描述][1]

其中，如下图所示，计算单元主要执行算术运算、移位等操作以及地址运算和转换；存储单元主要用于保存运算中产生的数据以及指令等；控制单元则对指令译码，并且发出为完成每条指令所要执行的各个操作的控制信号。

![此处输入图片的描述][2]

### 性能参数
#### 主频
主频也叫时钟频率，单位是兆赫（MHz）或千兆赫（GHz），用来表示CPU的运算、处理数据的速度。
#### 外频
外频是CPU的基准频率，单位是MHz。CPU的外频决定着整块主板的运行速度。
#### 总线频率
前端总线（FSB)是将CPU连接到北桥芯片的总线。前端总线（FSB）频率（即总线频率）是直接影响CPU与内存直接数据交换速度。
#### 倍频系数
倍频系数是指CPU主频与外频之间的相对比例关系。在相同的外频下，倍频越高CPU的频率也越高。
#### 缓存
缓存大小也是CPU的重要指标之一，而且缓存的结构和大小对CPU速度的影响非常大，CPU内缓存的运行频率极高，一般是和处理器同频运作，工作效率远远大于系统内存和硬盘。具体又分为L1/L2/L3三层。

### 厂商 ###
#### 1.Intel公司 ####
Intel是生产CPU的老大哥，它占有大约80%的市场份额，Intel生产的CPU就成了事实上的x86CPU技术规范和标准。

#### 2·AMD公司 ####
除了Intel公司外，最有力的挑战的就是AMD公司。AMD公司专门为计算机、通信和消费电子行业设计和制造各种创新的微处理器（CPU、GPU、APU、主板芯片组、电视卡芯片等)、闪存和低功率处理器解决方案
#### 3·Cyrix ####
曾经风靡一时的世界第三大CPU生产厂家，现在被VIA与AMD分别收购生产线与技术。
#### 4·IBM公司 ####
国际商业机器公司IBM，拥有了自己的芯片生产线，主要生产服务器用POWER处理器。

---
## GPU ##
### 简介 ###
图形处理器（英语：Graphics Processing Unit，缩写：GPU），又称显示核心、视觉处理器、显示芯片，是一种专门在个人电脑、工作站、游戏机和一些移动设备（如平板电脑、智能手机等）上图像运算工作的微处理器。

用途是将计算机系统所需要的显示信息进行转换驱动，并向显示器提供行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要元件，也是“人机对话”的重要设备之一。显卡作为电脑主机里的一个重要组成部分，承担输出显示图形的任务，对于从事专业图形设计的人来说显卡非常重要。

工作原理上简单地说，GPU就是能够从硬件上支持T&L（Transform and Lighting，多边形转换和光源处理）的显示芯片，由于T&L是3D渲染中的一个重要部分，其作用是计算多边形的3D位置与处理动态光线效果，也能称为“几何处理”。一个好的T&L单元，能提供细致的3D物体和高级的光线特效；只不过大多数PC中，T&L的大部分运算是交由CPU处理的(这就也就是所谓软件T&L)，因为CPU的任务繁多，除了T&L之外，还要做内存管理和输入响应等非3D图形处理工作，所以在实际运算的时候性能会大打折扣，一般出现显卡等待CPU数据的情况，CPU运算速度远跟不上时下复杂三维游戏的要求。即使CPU的工作频率超出1GHz或更高，对它的帮助也不大，因为这是PC本身设计造成的问题，与CPU的速度无太大关系。

为什么GPU特别擅长处理图像数据呢？这是因为图像上的每一个像素点都有被处理的需要，而且每个像素点处理的过程和方式都十分相似，也就成了GPU的天然温床。

GPU简单架构如下图所示：

![此处输入图片的描述][3]

但有一点需要强调，虽然GPU是为了图像处理而生的，但是我们通过前面的介绍可以发现，它在结构上并没有专门为图像服务的部件，只是对CPU的结构进行了优化与调整，所以现在GPU不仅可以在图像处理领域大显身手，它还被用来科学计算、密码破解、数值分析，海量数据处理（排序，Map-Reduce等），金融分析等需要大规模并行计算的领域。

所以GPU也可以认为是一种较通用的芯片。
### 类型 ###
#### 独立显卡 ####
显卡是通过PCI-Express、PCI或AGP等扩展槽界面与主板连接的，而通常它们可以相对容易地被取代或升级（假设主板能支持升级）。现在，仍然有少数显卡采用带宽有限的PCI插槽作连接，但它们通常只会在主板没有提供PCI-Express和AGP插槽的情况下才会使用。
在现今的定义里，独立绘图处理器不一定需要，是可以被移除的，也不一定要直接与主板连接。所谓的“专用”即是指独立显卡（或称专用显卡）内的RAM只会被该卡专用，而不是指显卡是否可从主板上独立移除。基于体积和重量的限制，供笔记本电脑使用的独立绘图处理器通常会通过非标准或独特的接口作连接。然而，由于逻辑接口相同，这些端口仍会被视为PCI-Express或AGP，即使它们在物理上是不可与其他显卡互换的。
一些特别的技术，如NVIDIA的SLI和ATI的CrossFire允许多个绘图处理器共同处理一个单一的视频输出，可令电脑的图像处理能力增加。
#### 集成绘图处理器 ####
集成绘图处理器（或称内置显示核心）是设在主板或CPU上的绘图处理器，运作时会借用电脑内部分的系统存储器。2007年装设集成显示的个人电脑约占总出货量的90%，相比起使用独立显卡的方案，这种方案可能较为便宜，但性能也许相对较低。从前，集成绘图处理器往往会被认为是不适合于运行3D游戏或精密的图形型运算。然而，如Intel GMA X3000（Intel G965 芯片组）、AMD的Radeon HD 4290（AMD 890GX 芯片组）和NVIDIA的GeForce 8200（NVIDIAnForce 730a芯片组）已有能力处理对系统需求不是太高的3D图像。当时较旧的集成图形处理器组缺乏如硬件T&L等功能，只有较新型号才会包含。
影响集成绘图处理器的性能，其中一个原因是由于内置显示核心的运算速度。同时，图形处理器在运作时会消耗一定数量的存储器。系统存储器的速度比高级独立绘图存储器来得慢，系统存储器的发送速度可能是10GB/s至20GB/s左右，独立绘图存储器则至少有50GB/s，甚至超过150GB/s，取决于型号而定。
不过从2009年开始，图形处理器已经从主板移去处理器了，如Intel的Westmere架构至目前的Kaby Lake架构。不过极致版并没有集成图形处理器。集成至处理器的好处是由于绘图及处理器芯片工艺为相同(Westmere除外，CPU为32nm而GPU为45nm)，可以减低热功耗。随着内显技术的成熟，目前的内显已经足够应付基本3D的需求，不过仍然依赖主板本身的存储器。

### 性能指标 ###
#### 显存位宽 ####
指一个时钟周期内能传输数据的位数。主流256 bit 和 512 bit。

#### 显存类型 ####
和电脑的运行内存一样，主流为DDR3与DDR5。

#### 显存带宽 ####
指每秒能传输的数据量。 
显存带宽=显存频率X显存带宽/8/1000 (GB/s) 
eg: GeForce GTX 1060 显存频率8008MHz，显示位宽192bit 
则：显存带宽=8008X192/8/1000(GB/s)=192.2 GB/s
#### 显存频率 ####
指默认情况下显存在显卡上的工作频率，厂商设定的工作频率一般比最大频率小。
#### 显存容量 ####
用来存储显卡芯片即将处理和处理完的数据，对显卡性能影响较小，当容量大于GPU的性能时多余的容量是浪费。
#### 核心频率 ####
GPU的运算频率，与计算机的主频差不多。
#### shader 频率 ####
即着色器频率，它是DirectX 10统一渲染架构（Unified Shader Architecture）诞生后出现的新产物。
#### 制作工艺 ####
制作工艺指的是晶体管与晶体管之间的距离，制作工艺越小说明集成度越高，只会影响到功耗，对性能并没有影响。


### 厂商 ###
#### 英特尔 ####
英特尔的GPU基本为集成显卡芯片，用于英特尔的主板和英特尔的CPU。可能你想不到，要是只按市场占有率计算，英特尔随着他主板及CPU发售的集成GPU占据了整个GPU市场的60%以上。
他的GPU主要有：唯一一款独立显卡芯片Intel 740（i740）。Extreme Graphics系列、GMA系列（集成于芯片组中）。现在的HD Graphics系列 [1]  、Iris™ Graphics系列 [2]  、Iris™ Pro Graphics [2]  系列等（集成于CPU中）。
#### NVIDIA ####
NVIDIA是现在最大的独立显卡芯片生产销售商。
他的GPU包括大家熟悉的Geforce系列 [3]  ，包括GTX、GTS、GT等。专业工作站的Quadro系列 [4]  ，超级计算的Tesla系列 [5]  ，多显示器商用的NVS系列 [6]  ，移动设备的Tegra系列 [7]  。
以前也销售集成在主板上的集成显卡芯片，这些随着主板芯片组一起发售，但是由于AMD收购ATI后自身主板芯片组GPU能力提高，NVIDIA芯片组如日中天的景象已经消失了。
曾经为游戏机Xbox、PS3供应GPU。
#### AMD(ATI) ####
AMD是世界上第二大的独立显卡芯片生产销售商，他的前身就是ATI，2006年AMD以54亿美元收购ATI。
他的GPU主要是大家熟悉的Radeon系列 [8]  ，包括以前的X、HD系列，近几年的R9、R7、R5、R3，现在的RX系列等。专业工作站的FireGL系列，超级计算的FireStream系列，多显示器商用的FireMV系列，现在前三者已合并为FirePro系列 [9]  。
早期ATI还生产过Wonder系列、Mach系列、Rage系列芯片。
除了独立显卡之外AMD还拥有集成显卡芯片，集成于芯片组、APU中。
由于AMD收购ATI后，其主板市场迅速扩大，已经夺取了NVIDIA在AMD处理器主板芯片组的半壁江山。
就现在的发售量和发售盈利方面，AMD的GPU市场占有率方面仍然略输于NVIDIA。
AMD也是游戏机Xbox 360、Wii、Wii U、PS4、Xbox One的GPU供应商。

---

## TPU ##
### 简介 ###
TPU，是Tensor Processing Unit的简称，是谷歌打造的处理器，是专为机器学习量身定做的，执行每个操作所需的晶体管数量更少，自然效率更高。

原来很多的机器学习以及图像处理算法大部分都跑在GPU与FPGA（半定制化芯片）上面，但这两种芯片都还是一种通用性芯片，所以在效能与功耗上还是不能更紧密的适配机器学习算法，而且Google一直坚信伟大的软件将在伟大的硬件的帮助下更加大放异彩，所以Google便想，我们可不可以做出一款专用机机器学习算法的专用芯片，TPU便诞生了。

据称，TPU与同期的CPU和GPU相比，可以提供15-30倍的性能提升，以及30-80倍的效率（性能/瓦特）提升。初代的TPU只能做推理，要依靠Google云来实时收集数据并产生结果，而训练过程还需要额外的资源；而第二代TPU既可以用于训练神经网络，又可以用于推理。

![此处输入图片的描述][4]
谷歌第二代TPU

![此处输入图片的描述][5]
TPU 各模块的框图

![此处输入图片的描述][6]
TPU芯片布局图

如上图所示，TPU在芯片上使用了高达24MB的局部内存，6MB的累加器内存以及用于与主控处理器进行对接的内存，总共占芯片面积的37%（图中蓝色部分）。

这表示谷歌充分意识到了片外内存访问是GPU能效比低的罪魁祸首，因此不惜成本的在芯片上放了巨大的内存。相比之下，英伟达同时期的K80只有8MB的片上内存，因此需要不断地去访问片外DRAM。

另外，TPU的高性能还来源于对于低运算精度的容忍。研究结果表明，低精度运算带来的算法准确率损失很小，但是在硬件实现上却可以带来巨大的便利，包括功耗更低、速度更快、占芯片面积更小的运算单元、更小的内存带宽需求等...TPU采用了8比特的低精度运算。

---
## NPU ##
### 简介 ###
NPU（Neural network Processing Unit）， 即神经网络处理器。也是针对神经网络来特别开发的处理器。神经网络中存储和处理是一体化的，都是通过突触权重来体现。而冯·诺伊曼结构中，存储和处理是分离的，分别由存储器和运算器来实现，二者之间存在巨大的差异。当用现有的基于冯·诺伊曼结构的经典计算机（如X86处理器和英伟达GPU）来跑神经网络应用时，就不可避免地受到存储和处理分离式结构的制约，因而影响效率。这也就是专门针对人工智能的专业芯片能够对传统芯片有一定先天优势的原因之一。

### 代表 ###
NPU的典型代表有国内的寒武纪芯片和IBM的TrueNorth。以中国的寒武纪为例，DianNaoYu指令直接面对大规模神经元和突触的处理，一条指令即可完成一组神经元的处理，并对神经元和突触数据在芯片上的传输提供了一系列专门的支持。

用数字来说话，CPU、GPU与NPU相比，会有百倍以上的性能或能耗比差距——以寒武纪团队过去和Inria联合发表的DianNao论文为例——DianNao为单核处理器，主频为0.98GHz，峰值性能达每秒4520亿次神经网络基本运算，65nm工艺下功耗为0.485W，面积3.02平方毫米mm。

### 备注 ###
中星微电子（Vimicro）的星光智能一号。中星微于2016年抢先发布了“星光智能一号”NPU。但是，这不是一个专为加速Neural Network而开发的处理器。虽说对外号称是NPU，但其实只是DSP，仅支持网络正向运算，无法支持神经网络训练。业内都知道其内部集成了多个DSP核（其称为NPU core），通过SIMD指令的调度来实现对CNN、DNN的支持。以这个逻辑，似乎很多芯片都可以叫NPU，其他以DSP为计算核心的SOC芯片的命名和宣传都相对保守了。

---

## 其他 ##
BPU -- Brain Processing Unit，
是由地平线科技提出的嵌入式人工智能处理器架构。第一代是高斯架构，第二代是伯努利架构，第三代是贝叶斯架构。目前地平线已经设计出了第一代高斯架构，并与英特尔在2017年CES展会上联合推出了ADAS系统（高级驾驶辅助系统）。

DPU -- Deep learning Processing Unit, 即深度学习处理器）最早由国内深鉴科技提出，基于Xilinx可重构特性的FPGA芯片，设计专用的深度学习处理单元（可基于已有的逻辑单元，设计并行高效的乘法器及逻辑电路，属于IP范畴），且抽象出定制化的指令集和编译器（而非使用OpenCL），从而实现快速的开发与产品迭代。事实上，深鉴提出的DPU属于半定制化的FPGA。

Dataflow Processing Unit。数据流处理器。创立于2010年的wave computing公司将其开发的深度学习加速处理器称为Dataflow Processing Unit(DPU)，应用于数据中心。Wave的DPU内集成1024个cluster。每个Cluster对应一个独立的全定制版图，每个Cluster内包含8个算术单元和16个PE。其中，PE用异步逻辑设计实现，没有时钟信号，由数据流驱动，这就是其称为Dataflow Processor的缘由。使用TSMC 16nm FinFET工艺，DPU die面积大概400mm^2，内部单口sram至少24MB，功耗约为200W，等效频率可达10GHz，性能可达181TOPS。前面写过一篇他家DPU的分析，见传输门AI芯片|浅析Yann LeCun提到的两款Dataflow Chip。

APU -- Accelerated Processing Unit, 加速处理器，AMD公司推出加速图像处理芯片产品。

BPU -- Brain Processing Unit, 地平线公司主导的嵌入式处理器架构。

EPU -- Emotion Processing Unit，
Emoshape 并不是这两年才推出EPU的，号称是全球首款情绪合成（emotion synthesis）引擎，可以让机器人具有情绪。但是，从官方渠道消息看，EPU本身并不复杂，也不需要做任务量巨大的神经网络计算，是基于MCU的芯片。结合应用API以及云端的增强学习算法，EPU可以让机器能够在情绪上了解它们所读或所看的内容。结合自然语言生成(NLG)及WaveNet技术，可以让机器个性化的表达各种情绪。例如，一部能够朗读的Kindle，其语音将根据所读的内容充满不同的情绪状态。

FPU -- Floating Processing Unit 浮点计算单元，通用处理器中的浮点运算模块。

HPU -- Holographics Processing Unit 全息图像处理器， 微软出品的全息计算芯片与设备。

IPU -- Intelligence Processing Unit， Deep Mind投资的Graphcore公司出品的AI处理器产品。

MPU/MCU -- Microprocessor/Micro controller Unit， 微处理器/微控制器，一般用于低计算应用的RISC计算机体系架构产品，如ARM-M系列处理器。


QPU -- Quantum Processing Unit。量子处理器。量子计算机也是近几年比较火的研究方向。作者承认在这方面所知甚少。可以关注这家成立于1999年的公司D-Wave System。DWave大概每两年可以将其QPU上的量子位个数翻倍一次。

RPU -- 
Radio Processing Unit, 无线电处理器， Imagination Technologies 公司推出的集合集Wifi/蓝牙/FM/处理器为单片的处理器。

Resistive Processing Unit。阻抗处理单元RPU。这是IBM Watson Research Center的研究人员提出的概念，真的是个处理单元，而不是处理器。RPU可以同时实现存储和计算。利用RPU阵列，IBM研究人员可以实现80TOPS/s/W的性能。

Ray-tracing Processing Unit。光线追踪处理器。Ray tracing是计算机图形学中的一种渲染算法，RPU是为加速其中的数据计算而开发的加速器。现在这些计算都是GPU的事情了。

SPU -- Streaming Processing Unit， 流处理器。流处理器的概念比较早了，是用于处理视频数据流的单元，一开始出现在显卡芯片的结构里。可以说，GPU就是一种流处理器。甚至，还曾经存在过一家名字为“Streaming Processor Inc”的公司，2004年创立，2009年，随着创始人兼董事长被挖去NVIDIA当首席科学家，SPI关闭。

TPU -- Tensor Processing Unit 张量处理器， Google 公司推出的加速人工智能算法的专用处理器。目前一代TPU面向Inference，二代面向训练。

VPU -- Vector Processing Unit 矢量处理器，Intel收购的Movidius公司推出的图像处理与人工智能的专用芯片的加速计算核心。

WPU -- Wearable Processing Unit， 可穿戴处理器，Ineda Systems公司推出的可穿戴片上系统产品，包含GPU/MIPS CPU等IP。

XPU -- 百度与Xilinx公司在2017年Hotchips大会上发布的FPGA智能云加速，含256核。

ZPU -- Zylin Processing Unit, 由挪威Zylin 公司推出的一款32位开源处理器。
---

### 总结 ###

总得来说，各种处理器，尤其是最新一段时间新发展出现的处理器大多都是根据具体使用需求和场景而特别定制开发的，不同的处理器有各自最为擅长的领域，我们应当根据实际情况来选择处理器，同时也要注意有部分新处理器并没有很多的开创性和优势，所以也不应当盲目迷信新处理器。

---
### 参考资料： ###
http://news.ifeng.com/a/20170830/51808889_0.shtml
https://www.sohu.com/a/200698604_160923
Wikipedia，Baidupedia


[1]: http://5b0988e595225.cdn.sohucs.com/images/20171028/e664ed39638648469655f0fefe19f731.png
[2]: http://5b0988e595225.cdn.sohucs.com/images/20171028/636a564e61c140bbbf2826cc9cbca527.jpeg
[3]: http://5b0988e595225.cdn.sohucs.com/images/20171028/e7ac26fc862a469983022f5078cf4bbb.png
[4]: http://5b0988e595225.cdn.sohucs.com/images/20171028/1b9a0bc769184d02b5e29822b56bc8ea.jpeg
[5]: http://5b0988e595225.cdn.sohucs.com/images/20171028/947a5391ed5e417587395e1d08104a10.jpeg
[6]: http://5b0988e595225.cdn.sohucs.com/images/20171028/cc49dbed99cf40238ba6f5b66dcdfeb4.jpeg

