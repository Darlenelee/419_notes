# Report 1

> Requirements:
>
> Technical report about Borg, Omega, Apollo, Sigma, Kubernetes
>
> - characteristics
> - pros&cons
> - comment

## Sigma

### 简述

Sigma是阿里巴巴公司的在线任务调度器，与之相对的还有离线任务调度器Fuxi。Sigma可以抢占资源，分配资源给在线任务。任务部署使用PouchContainer。

### 特性

- 混合部署  
  - 把集群混合起来，将不同类型的任务调度到相同的物理资源上，通过调度，资源隔离等控制手段, 保障SLO（服务水平目标），极大降低成本。
  - 阿里是通过Sigma与Fuxi共同作用实现的混部，它们之间则通过一个叫做“level 0”的层去协调，一般来说，在线任务延时敏感，不可重入，在资源优先级上都比较高，可以抢占离线任务的资源。
  - 在slave节点上同时存在Sigma Agent，Fuxi Agent，Level0-Agent，接受多种调度方式。

- 富容器Pouch
  - PouchContainer是Sigma调度的对象，它也具有相当多的特性，下面列出了一些其他容器没有的特性。
    - 兼容OCI标准。
    - 支持Kubernates API。
    - 支持磁盘空间隔离，网络带宽隔离。
    - p2p镜像分发
    - 支持相当多的内核版本（是因为阿里内部有很多较老的系统，版本无法更新，必须兼容那些程序）
    - 内核补丁、lxcfs实现的资源可见性控制。

- 弹性调度和资源分时复用
  - 因为在线任务的需求和时间是有关系的，在1:00-7:00间在线任务较少，此时可以增加离线任务的资源分配。
  - 这个做法需要较准确的预测压力，扩容缩容要稳定快速。

### 优缺点

我认为一些架构是设计者根据需要作出的选择，单纯看Sigma一个方案，不太好说有什么优缺点，所以我会用一些比较来说明。另外还会有一些共同的，等待解决的问题。

- Kubernetes
  - K8s较为新颖，未经过太多实践验证，可调度节点数在一万以下。Sigma掌控节点数可达数十万级别。
  - K8s开源，参与贡献者多。Sigma闭源。
  - K8s对资源的抽象统一，有很多可供扩展、重制的部分，更多像一个框架，而不是一个成熟完整的解决方案。
- Borg
  - Borg也支持混部，并且资源利用率要高于Sigma。
  - Sigma和Fuxi结合的做法不算好方案，以后应该会统一调度，这样就和Borg相似。
  - Borg能支持十万级别以上的节点数。
  - Borg有资源隔离，效果也类似容器，但概念上不如现在的容器这样健全，比如没有镜像。功能上也比不上Pouch。
- Mesos
  - Mesos支持十万级别节点的调度方案。
  - 两层调度，支持多种调度框架。
  - Mesos的隔离性要差很多，引入了Docker后要好一点，但还是比不上Pouch。
- 难题
  - 谷歌工程师在 [Borg,Omega, and Kubernetes：Lessons learned from three container-management systems over a decade](https://queue.acm.org/detail.cfm?id=2898444) 中提出了一些问题。
  - 配置。不论是关于容器的配置还是应用程序的配置，一个可靠的配置管理并不容易。
  - 依赖条件管理，即不仅管理部署的应用，还能管理与它相关联的应用，比如监控、存储。
  - 并未听说Sigma有解决这些问题。

### 评价

- Sigma是一个优秀的项目，它帮助阿里实现了容器化迁移，提升资源利用率（日均cpu利用率从10%变为40%），节约了成本。

- Sigma始终是一个闭源的项目，我觉得它应该对标谷歌的Borg，但现在谷歌已经到了下一代项目kubernetes。听说阿里也会积极参与，最终应该会有一个更好的解决方案，在线离线统一调度将会进一步加强资源利用。

---

# Apollo
### ——a highly scalable and coordinated scheduling framework
---
##Introduction
Apollo是一个用于集群管理的具有高度可扩展性的协调调度框架，目前正被微软部署应用于管理其业务。Apollo日常通过运算协调调度上万台机器中运行的百万数量级的事务，且运作过程表现良好，系统也十分健壮，能够处理意外的系统动态变化的情况。

---
##Features
1. 出于平衡集群规模的可伸缩性和调度工作的质量的考虑，Apollo采用了一种分布式的松散连接协调框架。每个节点在综合考虑根据整个集群的信息之后再独立地进行调度抉择。
2. Apollo建立了一个评估模型，该模型综合考虑多项因素，使得调度框架可以执行加权决策而非仅仅考虑服务器负载或数据局部性等某些单独的因素。此外，这个模型还可以通过并行计算实现任务执行过程中收集数据来细化评估结果，提高模型的精确性。
3. Apollo还提供了一系列的修正机制来应对集群运行过程中出现的一些意外情况和修正一些非最优的调度抉择。例如具体方法有：延迟修正机制，即仅当独立调度器之间的冲突具有显著影响时，才允许解决这些冲突等。
4. Apollo引入了机会调度的机制来达到在不影响调度作业效率的情况下提高集群资源的利用率的目标。在这个机制下所有事务都被划分成了两类，即常规事务和机会事务。这个机制在确保常规事务的低延迟响应时间的基础上再让机会事务尽可能充分利用常规事务所剩余的时间。另外Apollo还进一步采用了基于token的机制来管理容量资源，并通过限制常规事务的总数的方法来避免系统过载。
5. 为了解决实际应用中更换集群管理框架过程中很容易出现的服务中断和性能倒退的问题，Apollo的框架中设计了分阶段推出和大规模验证的机制来解决这一问题。
6. 在架构上有着Job Manager、Resource Monitor、Process Node等多级结构，具体见下图：
![此处输入图片的描述][1]
上图中Job Manager（JM）就是一个调度器，它负责对作业进行调度，每一个集群都会拥有一个Resource Monitor（RM），每一台服务器都拥有一个Process Node（PN），它们两个协调工作来为调度器提供一个全局的视角，供调度器进行调度决策时使用。每个PN负责对本地服务器的资源进行管理，RM会从集群 中每个服务器上的PN那里收集信息，汇总成全局信息后给每个JM。

---
##Pros
1. 分布式的松散连接协调架构避免了完全分布式调度系统下很可能产生的调度抉择冲突问题，即局部最优并非整体最优；同时在可扩展性上又比传统的中心式框架要好很多，尽可能达到了最好的平衡。
2. Apollo的评估模型可以尽可能达到最小化每项任务完成时间的目标。
3. 修正机制能够实现运行时动态调度调整和纠正非最优的调度决策等目标。
4. 机会调度的机制尽可能提高了集群资源的利用率。
5. 设计中还考虑了实际运用中更换框架的过程中可能出现的问题，与生产环境较为贴合。

---
##Comment
Apollo整体架构很有特点，它的结构体现了一种类似松散耦合的思想。Apollo在采用分布式架构的同时，又将整个集群的信息共享给每一个节点，这种设计避免了服务器负载不均衡和调度决策冲突等性能问题，还使得整个系统的可扩展性较高，从而更加适于大规模的集群管理，Apollo能够日常处理微软庞大的业务量也具体体现了其各方面性能的优越。

  [1]: https://raw.githubusercontent.com/Darlenelee/419_notes/master/Image/ApolloStrcture.png
